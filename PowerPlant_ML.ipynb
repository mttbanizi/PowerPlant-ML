{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyOOCY8hEFWG8ex+pUAt7Z+y",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/mttbanizi/PowerPlant-ML/blob/main/PowerPlant_ML.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "```\n",
        "https://rosenfelder.ai/multi-input-neural-network-pytorch/\n",
        "```\n",
        "\n"
      ],
      "metadata": {
        "id": "9Lzc_BDVzNrF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pip install pytesseract"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bviYlSm7bLGh",
        "outputId": "e60d176a-5b82-4186-d3ef-ad0d46d85a15"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting pytesseract\n",
            "  Downloading pytesseract-0.3.10-py3-none-any.whl (14 kB)\n",
            "Requirement already satisfied: packaging>=21.3 in /usr/local/lib/python3.10/dist-packages (from pytesseract) (23.1)\n",
            "Requirement already satisfied: Pillow>=8.0.0 in /usr/local/lib/python3.10/dist-packages (from pytesseract) (9.4.0)\n",
            "Installing collected packages: pytesseract\n",
            "Successfully installed pytesseract-0.3.10\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "JuIm6eag0rvL"
      },
      "outputs": [],
      "source": [
        "import cv2\n",
        "import pytesseract\n",
        "import numpy as np"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# image = cv2.imread('7.jpg')"
      ],
      "metadata": {
        "id": "fPpgl2IhZFBx"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Read the CSV file into a pandas DataFrame\n",
        "csv_file_path = 'data.csv'  # Replace with the actual path to your CSV file\n",
        "data_frame = pd.read_csv(csv_file_path)\n",
        "\n",
        "# Now you can work with the pandas DataFrame 'data_frame'\n",
        "# For example, you can print the first few rows of the DataFrame:\n",
        "print(data_frame.head())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ToZUoIQ8boyC",
        "outputId": "054bf604-1a0d-4f76-c04e-68574f4c2cb6"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   11 19:58  346.328  133.408  33.298  301.484  124.509  306.326  131.007\n",
            "0  11 20:58  310.272  142.474  32.017  396.497  125.188  436.629  131.780\n",
            "1  11 21:58  305.023  143.402  31.036  399.970  125.666  439.996  132.644\n",
            "2  11 22:58  246.803  145.404  30.811  399.976  117.174  439.991  123.214\n",
            "3  11 23:58  231.144  146.174  31.650  400.008  115.559  439.964  122.931\n",
            "4  12 00:58  220.564  147.361  30.994  399.911  116.726  439.964  124.278\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "new_column_titles = ['time', 'pressure', 'Steem MW', 'AmientTemp', 'B1_Flow', 'G1_MW', 'B2_Flow', 'G2_MW']\n",
        "\n",
        "# Assign the new column titles to the DataFrame\n",
        "data_frame.columns = new_column_titles"
      ],
      "metadata": {
        "id": "PeF8bOo4dki4"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(data_frame.head())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IcQy0lRrc5Kv",
        "outputId": "61ab9003-fbb0-48f3-ff39-aaffc89c4481"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "       time  pressure  Steem MW  AmientTemp  B1_Flow    G1_MW  B2_Flow  \\\n",
            "0  11 20:58   310.272   142.474      32.017  396.497  125.188  436.629   \n",
            "1  11 21:58   305.023   143.402      31.036  399.970  125.666  439.996   \n",
            "2  11 22:58   246.803   145.404      30.811  399.976  117.174  439.991   \n",
            "3  11 23:58   231.144   146.174      31.650  400.008  115.559  439.964   \n",
            "4  12 00:58   220.564   147.361      30.994  399.911  116.726  439.964   \n",
            "\n",
            "     G2_MW  \n",
            "0  131.780  \n",
            "1  132.644  \n",
            "2  123.214  \n",
            "3  122.931  \n",
            "4  124.278  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# data_frame['Flow'] = data_frame['B1_Flow'].astype(float) + data_frame['B2_Flow'].astype(float)\n",
        "data_frame['G_MW'] = data_frame['G1_MW'].astype(float) + data_frame['G2_MW'].astype(float)\n",
        "print(data_frame.head())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-Whglxy5e49B",
        "outputId": "cd7af893-f5b3-4a32-d2de-3f3335e215fc"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "       time  pressure  Steem MW  AmientTemp  B1_Flow    G1_MW  B2_Flow  \\\n",
            "0  11 20:58   310.272   142.474      32.017  396.497  125.188  436.629   \n",
            "1  11 21:58   305.023   143.402      31.036  399.970  125.666  439.996   \n",
            "2  11 22:58   246.803   145.404      30.811  399.976  117.174  439.991   \n",
            "3  11 23:58   231.144   146.174      31.650  400.008  115.559  439.964   \n",
            "4  12 00:58   220.564   147.361      30.994  399.911  116.726  439.964   \n",
            "\n",
            "     G2_MW     G_MW  \n",
            "0  131.780  256.968  \n",
            "1  132.644  258.310  \n",
            "2  123.214  240.388  \n",
            "3  122.931  238.490  \n",
            "4  124.278  241.004  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# print(data_frame)"
      ],
      "metadata": {
        "id": "92mIBmXsqKyH"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data_frame.at[37,'B1_Flow'] = 400"
      ],
      "metadata": {
        "id": "8ITBBLyfhD1D"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# result = data_frame[data_frame['B1_Flow'].str.contains('r')]\n",
        "# print(result)"
      ],
      "metadata": {
        "id": "5CjA4UDPgkEZ"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data_frame['Flow'] = data_frame['B1_Flow'].astype(float) + data_frame['B2_Flow'].astype(float)\n",
        "print(data_frame.head())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "P6c81P9CgNqR",
        "outputId": "e021e165-3363-4016-d49e-3937b9890ef0"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "       time  pressure  Steem MW  AmientTemp  B1_Flow    G1_MW  B2_Flow  \\\n",
            "0  11 20:58   310.272   142.474      32.017  396.497  125.188  436.629   \n",
            "1  11 21:58   305.023   143.402      31.036  399.970  125.666  439.996   \n",
            "2  11 22:58   246.803   145.404      30.811  399.976  117.174  439.991   \n",
            "3  11 23:58   231.144   146.174      31.650  400.008  115.559  439.964   \n",
            "4  12 00:58   220.564   147.361      30.994  399.911  116.726  439.964   \n",
            "\n",
            "     G2_MW     G_MW     Flow  \n",
            "0  131.780  256.968  833.126  \n",
            "1  132.644  258.310  839.966  \n",
            "2  123.214  240.388  839.967  \n",
            "3  122.931  238.490  839.972  \n",
            "4  124.278  241.004  839.875  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data_frame_Modified = data_frame.drop(columns=['B1_Flow','B2_Flow','G1_MW', 'G2_MW'])\n",
        "data_frame_Modified = data_frame_Modified.sort_values(by='Steem MW')"
      ],
      "metadata": {
        "id": "1vp76WrFhkO1"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data_frame_Modified = data_frame_Modified.reset_index(drop=True)"
      ],
      "metadata": {
        "id": "7D46Rn8a25dm"
      },
      "execution_count": 67,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(data_frame_Modified)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dOCDpEfWiNtf",
        "outputId": "8772f192-44a8-483e-e02a-42e20939cfb6"
      },
      "execution_count": 69,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "        time  pressure  Steem MW  AmientTemp     G_MW     Flow\n",
            "0   12 17:58   364.315   134.021      35.901  256.289  626.694\n",
            "1   12 18:58   362.293   134.215      34.700  256.934  557.287\n",
            "2   12 16:58   350.456   134.935      37.516  255.058  626.297\n",
            "3   12 15:58   354.372   135.036      37.297  255.034  635.316\n",
            "4   12 19:58   340.949   135.883      33.254  258.033  626.033\n",
            "5   12 13:58   353.162   136.982      36.349  252.471  776.088\n",
            "6   12 12:58   350.716   137.837      35.653  252.708  778.697\n",
            "7   12 14:58   351.172   139.170      36.887  254.875  774.057\n",
            "8   13 06:58   214.926   139.477      28.271  224.637  860.056\n",
            "9   12 20:58   317.867   140.260      31.820  259.627  719.371\n",
            "10  13 15:58   368.036   140.814      35.498  258.806  863.453\n",
            "11  13 14:58   355.787   141.678      35.265  258.819  860.757\n",
            "12  12 11:58   318.158   141.781      34.941  253.240  844.711\n",
            "13  13 05:58   225.313   142.369      27.490  228.727  858.559\n",
            "14  13 16:58   347.637   142.401      35.474  259.599  862.544\n",
            "15  11 20:58   310.272   142.474      32.017  256.968  833.126\n",
            "16  13 18:58   344.738   142.723      32.645  261.321  860.691\n",
            "17  13 13:58   340.589   142.739      34.473  258.971  861.067\n",
            "18  13 10:58   328.704   143.244      32.063  260.691  837.915\n",
            "19  12 21:58   309.530   143.259      30.980  261.208  788.034\n",
            "20  13 19:58   339.278   143.261      31.121  262.632  858.343\n",
            "21  11 21:58   305.023   143.402      31.036  258.310  839.966\n",
            "22  13 17:58   329.201   143.764      33.853  260.040  861.642\n",
            "23  13 12:58   321.996   143.917      33.623  259.469  858.651\n",
            "24  13 11:58   314.033   143.975      33.042  260.183  830.228\n",
            "25  13 09:58   307.493   144.037      31.218  243.093  870.792\n",
            "26  12 10:58   296.827   144.174      35.850  253.725  867.691\n",
            "27  12 09:58   279.312   144.219      33.038  238.881  922.112\n",
            "28  13 08:58   287.263   144.221      30.264  239.468  885.155\n",
            "29  13 20:58   319.737   144.829      30.280  263.285  857.394\n",
            "30  11 22:58   246.803   145.404      30.811  240.388  839.967\n",
            "31  11 23:58   231.144   146.174      31.650  238.490  839.972\n",
            "32  12 22:58   257.095   146.290      31.230  246.584  819.705\n",
            "33  12 08:58   243.624   146.413      32.453  233.190  930.062\n",
            "34  12 07:58   239.880   147.191      32.833  235.733  930.011\n",
            "35  12 00:58   220.564   147.361      30.994  241.004  839.875\n",
            "36  12 01:58   222.142   147.563      30.120  242.032  840.044\n",
            "37  12 06:58   221.983   147.680      32.976  240.944  865.000\n",
            "38  13 07:58   241.234   148.391      29.982  243.177  860.040\n",
            "39  12 02:58   206.502   149.084      28.460  243.747  839.911\n",
            "40  13 00:58   238.099   149.276      31.324  242.732  890.039\n",
            "41  12 23:58   236.230   149.469      31.596  241.016  900.541\n",
            "42  13 21:58   259.899   149.525      30.156  265.022  839.695\n",
            "43  13 22:58   221.842   150.281      29.863  246.590  845.424\n",
            "44  12 03:58   196.750   150.464      26.505  247.965  839.966\n",
            "45  13 23:58   218.371   150.559      29.836  247.065  849.862\n",
            "46  13 02:58   222.636   150.643      28.907  246.385  862.788\n",
            "47  13 01:58   220.819   150.969      29.833  244.445  889.918\n",
            "48  12 05:58   189.785   151.004      27.540  247.174  840.019\n",
            "49  12 04:58   187.100   151.439      26.352  248.577  839.902\n",
            "50  13 04:58   210.308   152.010      27.535  249.395  859.888\n",
            "51  13 03:58   205.620   152.138      28.353  247.321  860.006\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from torch import nn\n",
        "import matplotlib.pyplot as plt"
      ],
      "metadata": {
        "id": "O2JC_drhjqK4"
      },
      "execution_count": 70,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X = data_frame_Modified['Flow'].values\n",
        "y = data_frame_Modified['Steem MW']\n"
      ],
      "metadata": {
        "id": "kLgGTa7YkTx-"
      },
      "execution_count": 71,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create train/test split\n",
        "train_split = int(0.8 * len(X)) # 80% of data used for training set, 20% for testing\n",
        "X_train, y_train = X[:train_split], y[:train_split]\n",
        "X_test, y_test = X[train_split:], y[train_split:]\n",
        "\n",
        "len(X_train), len(y_train), len(X_test), len(y_test)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "btVRfaLEkPBX",
        "outputId": "1e0a4344-39f5-45b0-cfe7-fa7a90dc494d"
      },
      "execution_count": 72,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(41, 41, 11, 11)"
            ]
          },
          "metadata": {},
          "execution_count": 72
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def plot_predictions(train_data=X_train,\n",
        "                     train_labels=y_train,\n",
        "                     test_data=X_test,\n",
        "                     test_labels=y_test,\n",
        "                     predictions=None):\n",
        "  \"\"\"\n",
        "  Plots training data, test data and compares predictions.\n",
        "  \"\"\"\n",
        "  plt.figure(figsize=(10, 7))\n",
        "\n",
        "  # Plot training data in blue\n",
        "  plt.scatter(train_data, train_labels, c=\"b\", s=4, label=\"Training data\")\n",
        "\n",
        "  # Plot test data in green\n",
        "  plt.scatter(test_data, test_labels, c=\"g\", s=4, label=\"Testing data\")\n",
        "\n",
        "  if predictions is not None:\n",
        "    # Plot the predictions in red (predictions were made on the test data)\n",
        "    plt.scatter(test_data, predictions, c=\"r\", s=4, label=\"Predictions\")\n",
        "\n",
        "  # Show the legend\n",
        "  plt.legend(prop={\"size\": 14});"
      ],
      "metadata": {
        "id": "RUtzB8Orj2Yn"
      },
      "execution_count": 73,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plot_predictions();"
      ],
      "metadata": {
        "id": "rTXcauSzkvGV",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 599
        },
        "outputId": "0ce56255-f6e7-4807-b5a9-ae020726c33e"
      },
      "execution_count": 74,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1000x700 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class PowerPredictionModel(nn.Module):\n",
        "    def __init__(self, input_dim):\n",
        "        super(PowerPredictionModel, self).__init__()\n",
        "        self.fc1 = nn.Linear(input_dim, 32)  # Input layer to hidden layer\n",
        "        self.fc2 = nn.Linear(32, 16)         # Hidden layer to another hidden layer\n",
        "        self.fc3 = nn.Linear(16, 1)\n",
        "                  # Final hidden layer to output\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = torch.relu(self.fc1(x))\n",
        "        x = torch.relu(self.fc2(x))\n",
        "        x =self.fc3(x)\n",
        "        return x\n",
        "\n",
        "# Initialize the model\n",
        "input_dim = 1  # Number of input features\n",
        "model = PowerPredictionModel(input_dim)\n"
      ],
      "metadata": {
        "id": "EWb02V6XnIlh"
      },
      "execution_count": 75,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.optim as optim"
      ],
      "metadata": {
        "id": "EsWfJMn8nWhE"
      },
      "execution_count": 76,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "criterion = nn.MSELoss()  # Mean Squared Error loss\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.001)\n"
      ],
      "metadata": {
        "id": "quGzdn5fnMXg"
      },
      "execution_count": 77,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "loss_fn = nn.BCEWithLogitsLoss()\n",
        "optimizer = torch.optim.SGD(model.parameters(), lr=0.1)"
      ],
      "metadata": {
        "id": "P2MMzINeDhyW"
      },
      "execution_count": 78,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "num_epochs = 100\n",
        "for epoch in range(num_epochs):\n",
        "    inputs = torch.tensor(X_train, dtype=torch.float32).unsqueeze(dim=1)\n",
        "    targets = torch.tensor(y_train, dtype=torch.float32).unsqueeze(dim=1)\n",
        "    input_dim = inputs.size(dim=0)\n",
        "    optimizer.zero_grad()\n",
        "    outputs = model(inputs)\n",
        "    loss = loss_fn(outputs, targets)\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "    print(f'Epoch [{epoch + 1}/{num_epochs}], Loss: {loss.item():.4f}')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d2B3WtzdnaoS",
        "outputId": "11cda22d-4c1f-45d4-87c8-9be1bfd0e661"
      },
      "execution_count": 79,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [1/100], Loss: 7115.6904\n",
            "Epoch [2/100], Loss: -1251713591803904.0000\n",
            "Epoch [3/100], Loss: -inf\n",
            "Epoch [4/100], Loss: -inf\n",
            "Epoch [5/100], Loss: nan\n",
            "Epoch [6/100], Loss: nan\n",
            "Epoch [7/100], Loss: nan\n",
            "Epoch [8/100], Loss: nan\n",
            "Epoch [9/100], Loss: nan\n",
            "Epoch [10/100], Loss: nan\n",
            "Epoch [11/100], Loss: nan\n",
            "Epoch [12/100], Loss: nan\n",
            "Epoch [13/100], Loss: nan\n",
            "Epoch [14/100], Loss: nan\n",
            "Epoch [15/100], Loss: nan\n",
            "Epoch [16/100], Loss: nan\n",
            "Epoch [17/100], Loss: nan\n",
            "Epoch [18/100], Loss: nan\n",
            "Epoch [19/100], Loss: nan\n",
            "Epoch [20/100], Loss: nan\n",
            "Epoch [21/100], Loss: nan\n",
            "Epoch [22/100], Loss: nan\n",
            "Epoch [23/100], Loss: nan\n",
            "Epoch [24/100], Loss: nan\n",
            "Epoch [25/100], Loss: nan\n",
            "Epoch [26/100], Loss: nan\n",
            "Epoch [27/100], Loss: nan\n",
            "Epoch [28/100], Loss: nan\n",
            "Epoch [29/100], Loss: nan\n",
            "Epoch [30/100], Loss: nan\n",
            "Epoch [31/100], Loss: nan\n",
            "Epoch [32/100], Loss: nan\n",
            "Epoch [33/100], Loss: nan\n",
            "Epoch [34/100], Loss: nan\n",
            "Epoch [35/100], Loss: nan\n",
            "Epoch [36/100], Loss: nan\n",
            "Epoch [37/100], Loss: nan\n",
            "Epoch [38/100], Loss: nan\n",
            "Epoch [39/100], Loss: nan\n",
            "Epoch [40/100], Loss: nan\n",
            "Epoch [41/100], Loss: nan\n",
            "Epoch [42/100], Loss: nan\n",
            "Epoch [43/100], Loss: nan\n",
            "Epoch [44/100], Loss: nan\n",
            "Epoch [45/100], Loss: nan\n",
            "Epoch [46/100], Loss: nan\n",
            "Epoch [47/100], Loss: nan\n",
            "Epoch [48/100], Loss: nan\n",
            "Epoch [49/100], Loss: nan\n",
            "Epoch [50/100], Loss: nan\n",
            "Epoch [51/100], Loss: nan\n",
            "Epoch [52/100], Loss: nan\n",
            "Epoch [53/100], Loss: nan\n",
            "Epoch [54/100], Loss: nan\n",
            "Epoch [55/100], Loss: nan\n",
            "Epoch [56/100], Loss: nan\n",
            "Epoch [57/100], Loss: nan\n",
            "Epoch [58/100], Loss: nan\n",
            "Epoch [59/100], Loss: nan\n",
            "Epoch [60/100], Loss: nan\n",
            "Epoch [61/100], Loss: nan\n",
            "Epoch [62/100], Loss: nan\n",
            "Epoch [63/100], Loss: nan\n",
            "Epoch [64/100], Loss: nan\n",
            "Epoch [65/100], Loss: nan\n",
            "Epoch [66/100], Loss: nan\n",
            "Epoch [67/100], Loss: nan\n",
            "Epoch [68/100], Loss: nan\n",
            "Epoch [69/100], Loss: nan\n",
            "Epoch [70/100], Loss: nan\n",
            "Epoch [71/100], Loss: nan\n",
            "Epoch [72/100], Loss: nan\n",
            "Epoch [73/100], Loss: nan\n",
            "Epoch [74/100], Loss: nan\n",
            "Epoch [75/100], Loss: nan\n",
            "Epoch [76/100], Loss: nan\n",
            "Epoch [77/100], Loss: nan\n",
            "Epoch [78/100], Loss: nan\n",
            "Epoch [79/100], Loss: nan\n",
            "Epoch [80/100], Loss: nan\n",
            "Epoch [81/100], Loss: nan\n",
            "Epoch [82/100], Loss: nan\n",
            "Epoch [83/100], Loss: nan\n",
            "Epoch [84/100], Loss: nan\n",
            "Epoch [85/100], Loss: nan\n",
            "Epoch [86/100], Loss: nan\n",
            "Epoch [87/100], Loss: nan\n",
            "Epoch [88/100], Loss: nan\n",
            "Epoch [89/100], Loss: nan\n",
            "Epoch [90/100], Loss: nan\n",
            "Epoch [91/100], Loss: nan\n",
            "Epoch [92/100], Loss: nan\n",
            "Epoch [93/100], Loss: nan\n",
            "Epoch [94/100], Loss: nan\n",
            "Epoch [95/100], Loss: nan\n",
            "Epoch [96/100], Loss: nan\n",
            "Epoch [97/100], Loss: nan\n",
            "Epoch [98/100], Loss: nan\n",
            "Epoch [99/100], Loss: nan\n",
            "Epoch [100/100], Loss: nan\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.eval()\n",
        "with torch.no_grad():\n",
        "    test_inputs = torch.tensor(X_test, dtype=torch.float32).unsqueeze(dim=1)\n",
        "    predictions = model(test_inputs)\n",
        "\n",
        "# Calculate the evaluation metrics (e.g., RMSE, MAE)\n",
        "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
        "\n",
        "mse = mean_squared_error(y_test, predictions.numpy())\n",
        "rmse = mse ** 0.5\n",
        "mae = mean_absolute_error(y_test, predictions.numpy())\n",
        "\n",
        "print(f'RMSE: {rmse:.4f}, MAE: {mae:.4f}')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 429
        },
        "id": "PjyyPXuAnihs",
        "outputId": "7922d23b-fb4c-4d8a-c406-8ad7bccdbf12"
      },
      "execution_count": 80,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-80-be00f418fe0f>\u001b[0m in \u001b[0;36m<cell line: 9>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmetrics\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mmean_squared_error\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmean_absolute_error\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m \u001b[0mmse\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmean_squared_error\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpredictions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m \u001b[0mrmse\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmse\u001b[0m \u001b[0;34m**\u001b[0m \u001b[0;36m0.5\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0mmae\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmean_absolute_error\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpredictions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_regression.py\u001b[0m in \u001b[0;36mmean_squared_error\u001b[0;34m(y_true, y_pred, sample_weight, multioutput, squared)\u001b[0m\n\u001b[1;32m    440\u001b[0m     \u001b[0;36m0.825\u001b[0m\u001b[0;34m...\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    441\u001b[0m     \"\"\"\n\u001b[0;32m--> 442\u001b[0;31m     y_type, y_true, y_pred, multioutput = _check_reg_targets(\n\u001b[0m\u001b[1;32m    443\u001b[0m         \u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmultioutput\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    444\u001b[0m     )\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_regression.py\u001b[0m in \u001b[0;36m_check_reg_targets\u001b[0;34m(y_true, y_pred, multioutput, dtype)\u001b[0m\n\u001b[1;32m    100\u001b[0m     \u001b[0mcheck_consistent_length\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    101\u001b[0m     \u001b[0my_true\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcheck_array\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mensure_2d\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 102\u001b[0;31m     \u001b[0my_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcheck_array\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_pred\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mensure_2d\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    103\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    104\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0my_true\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndim\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36mcheck_array\u001b[0;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, estimator, input_name)\u001b[0m\n\u001b[1;32m    919\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    920\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mforce_all_finite\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 921\u001b[0;31m             _assert_all_finite(\n\u001b[0m\u001b[1;32m    922\u001b[0m                 \u001b[0marray\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    923\u001b[0m                 \u001b[0minput_name\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minput_name\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36m_assert_all_finite\u001b[0;34m(X, allow_nan, msg_dtype, estimator_name, input_name)\u001b[0m\n\u001b[1;32m    159\u001b[0m                 \u001b[0;34m\"#estimators-that-handle-nan-values\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    160\u001b[0m             )\n\u001b[0;32m--> 161\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmsg_err\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    162\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    163\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: Input contains NaN."
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Setup device agnostic code\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "print(f\"Using device: {device}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KLwRqiT5id5C",
        "outputId": "d880057a-ea55-4f62-8a40-b1fbaec961d6"
      },
      "execution_count": 82,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using device: cpu\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X1 = data_frame_Modified[['pressure']].values\n",
        "X2 = data_frame_Modified['G_MW'].values\n",
        "X3 = data_frame_Modified['Flow'].values"
      ],
      "metadata": {
        "id": "voeoVC5UTUPm"
      },
      "execution_count": 83,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_split = int(0.8 * len(X)) # 80% of data used for training set, 20% for testing\n",
        "X1_train, X2_train, X3_train, y1_train = X1[:train_split], X2[:train_split], X3[:train_split], y[:train_split]\n",
        "X1_test, X2_test, X3_test, y1_test = X1[train_split:], X2[train_split:], X3[train_split:], y[train_split:]\n"
      ],
      "metadata": {
        "id": "Joi_wrD2T833"
      },
      "execution_count": 84,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from torch import nn\n",
        "class CircleModelV2(nn.Module):\n",
        "    def __init__(self, input_dim):\n",
        "        super().__init__()\n",
        "        self.features = nn.Sequential(\n",
        "          nn.Linear(in_features=input_dim, out_features=10),\n",
        "          nn.Linear(in_features=10, out_features=10),\n",
        "          nn.Linear(in_features=10, out_features=1),\n",
        "          # nn.ReLU() # <- add in ReLU activation function\n",
        "          # Can also put sigmoid in the model\n",
        "          # This would mean you don't need to use it on the predictions\n",
        "          # self.sigmoid = nn.Sigmoid()\n",
        "        )\n",
        "\n",
        "    def forward(self, X1):\n",
        "      # Intersperse the ReLU activation function between layers\n",
        "      X1_feature = self.features(X1)\n",
        "      # X2_feature = self.features(X2)\n",
        "      # X3_feature = self.features(X3)\n",
        "      # return torch.cat((X1_feature, X2_feature, X3_feature), 1)\n",
        "      return X1_feature\n",
        "      #  return self.layer_3(self.relu(self.layer_2(self.relu(self.layer_1(x)))))\n",
        "\n",
        "model_3 = CircleModelV2(input_dim=1).to(device)\n",
        "print(model_3)\n",
        "model_3.state_dict()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IlJf_IU_iEAV",
        "outputId": "297c7255-5e0c-4bb4-dae4-cb554cac6551"
      },
      "execution_count": 104,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CircleModelV2(\n",
            "  (features): Sequential(\n",
            "    (0): Linear(in_features=1, out_features=10, bias=True)\n",
            "    (1): Linear(in_features=10, out_features=10, bias=True)\n",
            "    (2): Linear(in_features=10, out_features=1, bias=True)\n",
            "  )\n",
            ")\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "OrderedDict([('features.0.weight',\n",
              "              tensor([[-0.7341],\n",
              "                      [-0.1727],\n",
              "                      [ 0.2089],\n",
              "                      [ 0.5163],\n",
              "                      [ 0.8073],\n",
              "                      [ 0.9110],\n",
              "                      [-0.7929],\n",
              "                      [ 0.2517],\n",
              "                      [-0.4301],\n",
              "                      [-0.1096]])),\n",
              "             ('features.0.bias',\n",
              "              tensor([-0.7485,  0.9109, -0.7340,  0.5345,  0.3514,  0.3250, -0.5406,  0.9090,\n",
              "                       0.2198,  0.1286])),\n",
              "             ('features.1.weight',\n",
              "              tensor([[-0.2787,  0.1327, -0.0474, -0.1449,  0.2716,  0.0705, -0.1750, -0.1601,\n",
              "                       -0.0151,  0.1766],\n",
              "                      [-0.0808, -0.1804, -0.1083, -0.2362,  0.1128,  0.2448, -0.2977,  0.0734,\n",
              "                        0.1634,  0.0573],\n",
              "                      [-0.1126,  0.1651,  0.1662,  0.1182, -0.0556, -0.0837,  0.0338, -0.0559,\n",
              "                       -0.0942,  0.2021],\n",
              "                      [ 0.2718, -0.0313, -0.0708,  0.0046, -0.0189,  0.0760,  0.0886, -0.2872,\n",
              "                       -0.1167,  0.2663],\n",
              "                      [ 0.1232, -0.0157, -0.1907, -0.1935, -0.2833, -0.1031,  0.1068,  0.2016,\n",
              "                        0.1460, -0.2795],\n",
              "                      [-0.1902, -0.0499,  0.3059,  0.0457, -0.0819,  0.1308, -0.1204, -0.2047,\n",
              "                        0.2308, -0.1438],\n",
              "                      [-0.0634, -0.3146,  0.2116,  0.2396,  0.1152, -0.2205, -0.3121, -0.2568,\n",
              "                        0.2358,  0.1518],\n",
              "                      [ 0.2661,  0.1657,  0.0800, -0.0031, -0.2405, -0.2709, -0.2958,  0.1295,\n",
              "                       -0.1553, -0.0636],\n",
              "                      [-0.1820, -0.0576, -0.2226, -0.2066,  0.1049, -0.0940,  0.1952, -0.1014,\n",
              "                       -0.2320, -0.0558],\n",
              "                      [-0.1533, -0.0967, -0.3010,  0.1769, -0.2202,  0.1589,  0.1435,  0.2259,\n",
              "                       -0.2426,  0.2274]])),\n",
              "             ('features.1.bias',\n",
              "              tensor([-0.1495,  0.1173,  0.2970, -0.0446, -0.0024, -0.0728, -0.2640,  0.1518,\n",
              "                      -0.3139,  0.1963])),\n",
              "             ('features.2.weight',\n",
              "              tensor([[ 0.2366,  0.2991, -0.0746, -0.2598,  0.0711,  0.1747, -0.3147, -0.0718,\n",
              "                       -0.1896, -0.0277]])),\n",
              "             ('features.2.bias', tensor([-0.1557]))])"
            ]
          },
          "metadata": {},
          "execution_count": 104
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.optim as optim\n",
        "# Create loss function\n",
        "loss_fn = nn.L1Loss()\n",
        "\n",
        "# Create optimizer\n",
        "optimizer = torch.optim.SGD(params=model_3.parameters(), # optimize newly created model's parameters\n",
        "                            lr=0.01)"
      ],
      "metadata": {
        "id": "2VYiBFy9f8Xb"
      },
      "execution_count": 92,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Setup loss and optimizer\n",
        "loss_fn = nn.BCEWithLogitsLoss()\n",
        "optimizer = torch.optim.SGD(model_3.parameters(), lr=0.1)"
      ],
      "metadata": {
        "id": "EqqyyiBFifyE"
      },
      "execution_count": 87,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Calculate accuracy (a classification metric)\n",
        "def accuracy_fn(y_true, y_pred):\n",
        "    correct = torch.eq(y_true, y_pred).sum().item() # torch.eq() calculates where two tensors are equal\n",
        "    acc = (correct / len(y_pred)) * 100\n",
        "    return acc"
      ],
      "metadata": {
        "id": "fNLjI9fjYSCK"
      },
      "execution_count": 88,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_test = list(y_test)"
      ],
      "metadata": {
        "id": "0sFsUkKduKB-"
      },
      "execution_count": 89,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X1_train, X1_test = torch.as_tensor(X1_train, dtype=torch.float32).to(device), torch.as_tensor(X1_test,  dtype=torch.float32).to(device)\n",
        "X2_train, X2_test = torch.as_tensor(X2_train, dtype=torch.float32).to(device), torch.as_tensor(X2_test, dtype=torch.float32).to(device)\n",
        "X3_train, X3_test = torch.as_tensor(X3_train).to(device), torch.as_tensor(X3_test).to(device)\n",
        "y_train, y_test = torch.as_tensor(y_train).to(device),  torch.as_tensor(y_test).to(device)\n"
      ],
      "metadata": {
        "id": "3xqWG9xAnBIS"
      },
      "execution_count": 101,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Fit the model\n",
        "torch.manual_seed(42)\n",
        "epochs = 100\n",
        "\n",
        "# Put all data on target device\n",
        "\n",
        "for epoch in range(epochs):\n",
        "    model_3.train()\n",
        "    # 1. Forward pass\n",
        "    # y_logits = model_3(X1_train, X2_train, X3_train)\n",
        "    input_dim = X1_train.size(dim=0)\n",
        "    y_logits = model_3(X1_train )\n",
        "    y_pred = torch.round(torch.sigmoid(y_logits)) # logits -> prediction probabilities -> prediction labels\n",
        "\n",
        "    # 2. Calculate loss and accuracy\n",
        "    loss = loss_fn(y_logits, y_train) # BCEWithLogitsLoss calculates loss using logits\n",
        "    acc = accuracy_fn(y_true=y_train,\n",
        "                      y_pred=y_pred)\n",
        "\n",
        "    # 3. Optimizer zero grad\n",
        "    optimizer.zero_grad()\n",
        "\n",
        "    # 4. Loss backward\n",
        "    loss.backward()\n",
        "\n",
        "    # 5. Optimizer step\n",
        "    optimizer.step()\n",
        "\n",
        "    ### Testing\n",
        "    model_3.eval()\n",
        "    with torch.inference_mode():\n",
        "      # 1. Forward pass\n",
        "      test_logits = model_3(X1_test).squeeze()\n",
        "      test_pred = torch.round(torch.sigmoid(test_logits)) # logits -> prediction probabilities -> prediction labels\n",
        "      # 2. Calcuate loss and accuracy\n",
        "      test_loss = loss_fn(test_logits, y_test)\n",
        "      test_acc = accuracy_fn(y_true=y_test,\n",
        "                             y_pred=test_pred)\n",
        "\n",
        "    # Print out what's happening\n",
        "    if epoch % 10 == 0:\n",
        "        print(f\"Epoch: {epoch} | Loss: {loss:.5f}, Accuracy: {acc:.2f}% | Test Loss: {test_loss:.5f}, Test Accuracy: {test_acc:.2f}%\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HcwyboYPiypk",
        "outputId": "864d2466-76ce-43dc-aa2f-0a75f31aa6fc"
      },
      "execution_count": 94,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/loss.py:101: UserWarning: Using a target size (torch.Size([41])) that is different to the input size (torch.Size([41, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  return F.l1_loss(input, target, reduction=self.reduction)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 0 | Loss: 142.72985, Accuracy: 0.00% | Test Loss: 150.77281, Test Accuracy: 0.00%\n",
            "Epoch: 10 | Loss: 142.72985, Accuracy: 0.00% | Test Loss: 150.77281, Test Accuracy: 0.00%\n",
            "Epoch: 20 | Loss: 142.72985, Accuracy: 0.00% | Test Loss: 150.77281, Test Accuracy: 0.00%\n",
            "Epoch: 30 | Loss: 142.72985, Accuracy: 0.00% | Test Loss: 150.77281, Test Accuracy: 0.00%\n",
            "Epoch: 40 | Loss: 142.72985, Accuracy: 0.00% | Test Loss: 150.77281, Test Accuracy: 0.00%\n",
            "Epoch: 50 | Loss: 142.72985, Accuracy: 0.00% | Test Loss: 150.77281, Test Accuracy: 0.00%\n",
            "Epoch: 60 | Loss: 142.72985, Accuracy: 0.00% | Test Loss: 150.77281, Test Accuracy: 0.00%\n",
            "Epoch: 70 | Loss: 142.72985, Accuracy: 0.00% | Test Loss: 150.77281, Test Accuracy: 0.00%\n",
            "Epoch: 80 | Loss: 142.72985, Accuracy: 0.00% | Test Loss: 150.77281, Test Accuracy: 0.00%\n",
            "Epoch: 90 | Loss: 142.72985, Accuracy: 0.00% | Test Loss: 150.77281, Test Accuracy: 0.00%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Subclass nn.Module to make our model\n",
        "class LinearRegressionModelV2(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        # Use nn.Linear() for creating the model parameters\n",
        "        self.linear_layer = nn.Linear(in_features=1,\n",
        "                                      out_features=1)\n",
        "\n",
        "    # Define the forward computation (input data x flows through nn.Linear())\n",
        "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
        "        return self.linear_layer(x)\n",
        "\n",
        "# Set the manual seed when creating the model (this isn't always need but is used for demonstrative purposes, try commenting it out and seeing what happens)\n",
        "torch.manual_seed(42)\n",
        "model_1 = LinearRegressionModelV2()\n",
        "model_1, model_1.state_dict()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DjnPo_3s4VYh",
        "outputId": "f72a045a-f7c3-40d4-bb9b-d66f65116198"
      },
      "execution_count": 97,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(LinearRegressionModelV2(\n",
              "   (linear_layer): Linear(in_features=1, out_features=1, bias=True)\n",
              " ),\n",
              " OrderedDict([('linear_layer.weight', tensor([[0.7645]])),\n",
              "              ('linear_layer.bias', tensor([0.8300]))]))"
            ]
          },
          "metadata": {},
          "execution_count": 97
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X2_train = X2_train.unsqueeze(dim=1)\n",
        "X2_test = X2_test.unsqueeze(dim=1)"
      ],
      "metadata": {
        "id": "-cEnl1p57GDr"
      },
      "execution_count": 110,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "epochs = 1000\n",
        "for epoch in range(epochs):\n",
        "    ### Training\n",
        "    model_1.train() # train mode is on by default after construction\n",
        "\n",
        "    # 1. Forward pass\n",
        "    y_pred = model_1(X2_train)\n",
        "\n",
        "    # 2. Calculate loss\n",
        "    loss = loss_fn(y_pred, y_train)\n",
        "\n",
        "    # 3. Zero grad optimizer\n",
        "    optimizer.zero_grad()\n",
        "\n",
        "    # 4. Loss backward\n",
        "    loss.backward()\n",
        "\n",
        "    # 5. Step the optimizer\n",
        "    optimizer.step()\n",
        "\n",
        "    ### Testing\n",
        "    model_1.eval() # put the model in evaluation mode for testing (inference)\n",
        "    # 1. Forward pass\n",
        "    with torch.inference_mode():\n",
        "        test_pred = model_1(X2_test)\n",
        "\n",
        "        # 2. Calculate the loss\n",
        "        test_loss = loss_fn(test_pred, y_test)\n",
        "\n",
        "    if epoch % 100 == 0:\n",
        "        print(f\"Epoch: {epoch} | Train loss: {loss} | Test loss: {test_loss}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jmVYayv24jHk",
        "outputId": "c4f65d75-37f1-43c7-e2f9-5c05fc520235"
      },
      "execution_count": 111,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/loss.py:101: UserWarning: Using a target size (torch.Size([41])) that is different to the input size (torch.Size([41, 1, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  return F.l1_loss(input, target, reduction=self.reduction)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/loss.py:101: UserWarning: Using a target size (torch.Size([11])) that is different to the input size (torch.Size([11, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  return F.l1_loss(input, target, reduction=self.reduction)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 0 | Train loss: 49.628666477110336 | Test loss: 505.3368835449219\n",
            "Epoch: 100 | Train loss: 49.628666477110336 | Test loss: 505.3368835449219\n",
            "Epoch: 200 | Train loss: 49.628666477110336 | Test loss: 505.3368835449219\n",
            "Epoch: 300 | Train loss: 49.628666477110336 | Test loss: 505.3368835449219\n",
            "Epoch: 400 | Train loss: 49.628666477110336 | Test loss: 505.3368835449219\n",
            "Epoch: 500 | Train loss: 49.628666477110336 | Test loss: 505.3368835449219\n",
            "Epoch: 600 | Train loss: 49.628666477110336 | Test loss: 505.3368835449219\n",
            "Epoch: 700 | Train loss: 49.628666477110336 | Test loss: 505.3368835449219\n",
            "Epoch: 800 | Train loss: 49.628666477110336 | Test loss: 505.3368835449219\n",
            "Epoch: 900 | Train loss: 49.628666477110336 | Test loss: 505.3368835449219\n"
          ]
        }
      ]
    }
  ]
}