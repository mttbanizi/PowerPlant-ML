{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyOFNz2zSkQTQiLo+PpatTo5",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/mttbanizi/PowerPlant-ML/blob/main/PowerPlant_ML.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "```\n",
        "https://rosenfelder.ai/multi-input-neural-network-pytorch/\n",
        "```\n",
        "\n"
      ],
      "metadata": {
        "id": "9Lzc_BDVzNrF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pip install pytesseract"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bviYlSm7bLGh",
        "outputId": "1395c389-5f58-451e-c4dd-c748452b4c01"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting pytesseract\n",
            "  Downloading pytesseract-0.3.10-py3-none-any.whl (14 kB)\n",
            "Requirement already satisfied: packaging>=21.3 in /usr/local/lib/python3.10/dist-packages (from pytesseract) (23.1)\n",
            "Requirement already satisfied: Pillow>=8.0.0 in /usr/local/lib/python3.10/dist-packages (from pytesseract) (9.4.0)\n",
            "Installing collected packages: pytesseract\n",
            "Successfully installed pytesseract-0.3.10\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "JuIm6eag0rvL"
      },
      "outputs": [],
      "source": [
        "import cv2\n",
        "import pytesseract\n",
        "import numpy as np"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# image = cv2.imread('7.jpg')"
      ],
      "metadata": {
        "id": "fPpgl2IhZFBx"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Read the CSV file into a pandas DataFrame\n",
        "csv_file_path = 'data.csv'  # Replace with the actual path to your CSV file\n",
        "data_frame = pd.read_csv(csv_file_path)\n",
        "\n",
        "# Now you can work with the pandas DataFrame 'data_frame'\n",
        "# For example, you can print the first few rows of the DataFrame:\n",
        "print(data_frame.head())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ToZUoIQ8boyC",
        "outputId": "8ea86988-afd1-4540-a981-d1cefebb01b3"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   11 19:58  346.328  133.408  33.298  301.484  124.509  306.326  131.007\n",
            "0  11 20:58  310.272  142.474  32.017  396.497  125.188  436.629  131.780\n",
            "1  11 21:58  305.023  143.402  31.036  399.970  125.666  439.996  132.644\n",
            "2  11 22:58  246.803  145.404  30.811  399.976  117.174  439.991  123.214\n",
            "3  11 23:58  231.144  146.174  31.650  400.008  115.559  439.964  122.931\n",
            "4  12 00:58  220.564  147.361  30.994  399.911  116.726  439.964  124.278\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "new_column_titles = ['time', 'pressure', 'Steem MW', 'AmientTemp', 'B1_Flow', 'G1_MW', 'B2_Flow', 'G2_MW']\n",
        "\n",
        "# Assign the new column titles to the DataFrame\n",
        "data_frame.columns = new_column_titles"
      ],
      "metadata": {
        "id": "PeF8bOo4dki4"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(data_frame.head())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IcQy0lRrc5Kv",
        "outputId": "bde223b3-5e9f-455f-96e8-a2454f8e5bf8"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "       time  pressure  Steem MW  AmientTemp  B1_Flow    G1_MW  B2_Flow  \\\n",
            "0  11 20:58   310.272   142.474      32.017  396.497  125.188  436.629   \n",
            "1  11 21:58   305.023   143.402      31.036  399.970  125.666  439.996   \n",
            "2  11 22:58   246.803   145.404      30.811  399.976  117.174  439.991   \n",
            "3  11 23:58   231.144   146.174      31.650  400.008  115.559  439.964   \n",
            "4  12 00:58   220.564   147.361      30.994  399.911  116.726  439.964   \n",
            "\n",
            "     G2_MW  \n",
            "0  131.780  \n",
            "1  132.644  \n",
            "2  123.214  \n",
            "3  122.931  \n",
            "4  124.278  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# data_frame['Flow'] = data_frame['B1_Flow'].astype(float) + data_frame['B2_Flow'].astype(float)\n",
        "data_frame['G_MW'] = data_frame['G1_MW'].astype(float) + data_frame['G2_MW'].astype(float)\n",
        "print(data_frame.head())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-Whglxy5e49B",
        "outputId": "a4afd47b-d7a8-4f19-d792-0246662a9099"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "       time  pressure  Steem MW  AmientTemp  B1_Flow    G1_MW  B2_Flow  \\\n",
            "0  11 20:58   310.272   142.474      32.017  396.497  125.188  436.629   \n",
            "1  11 21:58   305.023   143.402      31.036  399.970  125.666  439.996   \n",
            "2  11 22:58   246.803   145.404      30.811  399.976  117.174  439.991   \n",
            "3  11 23:58   231.144   146.174      31.650  400.008  115.559  439.964   \n",
            "4  12 00:58   220.564   147.361      30.994  399.911  116.726  439.964   \n",
            "\n",
            "     G2_MW     G_MW  \n",
            "0  131.780  256.968  \n",
            "1  132.644  258.310  \n",
            "2  123.214  240.388  \n",
            "3  122.931  238.490  \n",
            "4  124.278  241.004  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# print(data_frame)"
      ],
      "metadata": {
        "id": "92mIBmXsqKyH"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data_frame.at[37,'B1_Flow'] = 400"
      ],
      "metadata": {
        "id": "8ITBBLyfhD1D"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# result = data_frame[data_frame['B1_Flow'].str.contains('r')]\n",
        "# print(result)"
      ],
      "metadata": {
        "id": "5CjA4UDPgkEZ"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data_frame['Flow'] = data_frame['B1_Flow'].astype(float) + data_frame['B2_Flow'].astype(float)\n",
        "print(data_frame.head())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "P6c81P9CgNqR",
        "outputId": "d2ec32d8-d81c-4638-e5e0-6b65eafca97a"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "       time  pressure  Steem MW  AmientTemp  B1_Flow    G1_MW  B2_Flow  \\\n",
            "0  11 20:58   310.272   142.474      32.017  396.497  125.188  436.629   \n",
            "1  11 21:58   305.023   143.402      31.036  399.970  125.666  439.996   \n",
            "2  11 22:58   246.803   145.404      30.811  399.976  117.174  439.991   \n",
            "3  11 23:58   231.144   146.174      31.650  400.008  115.559  439.964   \n",
            "4  12 00:58   220.564   147.361      30.994  399.911  116.726  439.964   \n",
            "\n",
            "     G2_MW     G_MW     Flow  \n",
            "0  131.780  256.968  833.126  \n",
            "1  132.644  258.310  839.966  \n",
            "2  123.214  240.388  839.967  \n",
            "3  122.931  238.490  839.972  \n",
            "4  124.278  241.004  839.875  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data_frame_Modified = data_frame.drop(columns=['B1_Flow','B2_Flow','G1_MW', 'G2_MW'])\n",
        "data_frame_Modified = data_frame_Modified.sort_values(by='Steem MW')"
      ],
      "metadata": {
        "id": "1vp76WrFhkO1"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data_frame_Modified = data_frame_Modified.reset_index(drop=True)"
      ],
      "metadata": {
        "id": "7D46Rn8a25dm"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(data_frame_Modified)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dOCDpEfWiNtf",
        "outputId": "4704921c-d15a-4a21-c416-e5e755d4b670"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "        time  pressure  Steem MW  AmientTemp     G_MW     Flow\n",
            "0   12 17:58   364.315   134.021      35.901  256.289  626.694\n",
            "1   12 18:58   362.293   134.215      34.700  256.934  557.287\n",
            "2   12 16:58   350.456   134.935      37.516  255.058  626.297\n",
            "3   12 15:58   354.372   135.036      37.297  255.034  635.316\n",
            "4   12 19:58   340.949   135.883      33.254  258.033  626.033\n",
            "5   12 13:58   353.162   136.982      36.349  252.471  776.088\n",
            "6   12 12:58   350.716   137.837      35.653  252.708  778.697\n",
            "7   12 14:58   351.172   139.170      36.887  254.875  774.057\n",
            "8   13 06:58   214.926   139.477      28.271  224.637  860.056\n",
            "9   12 20:58   317.867   140.260      31.820  259.627  719.371\n",
            "10  13 15:58   368.036   140.814      35.498  258.806  863.453\n",
            "11  13 14:58   355.787   141.678      35.265  258.819  860.757\n",
            "12  12 11:58   318.158   141.781      34.941  253.240  844.711\n",
            "13  13 05:58   225.313   142.369      27.490  228.727  858.559\n",
            "14  13 16:58   347.637   142.401      35.474  259.599  862.544\n",
            "15  11 20:58   310.272   142.474      32.017  256.968  833.126\n",
            "16  13 18:58   344.738   142.723      32.645  261.321  860.691\n",
            "17  13 13:58   340.589   142.739      34.473  258.971  861.067\n",
            "18  13 10:58   328.704   143.244      32.063  260.691  837.915\n",
            "19  12 21:58   309.530   143.259      30.980  261.208  788.034\n",
            "20  13 19:58   339.278   143.261      31.121  262.632  858.343\n",
            "21  11 21:58   305.023   143.402      31.036  258.310  839.966\n",
            "22  13 17:58   329.201   143.764      33.853  260.040  861.642\n",
            "23  13 12:58   321.996   143.917      33.623  259.469  858.651\n",
            "24  13 11:58   314.033   143.975      33.042  260.183  830.228\n",
            "25  13 09:58   307.493   144.037      31.218  243.093  870.792\n",
            "26  12 10:58   296.827   144.174      35.850  253.725  867.691\n",
            "27  12 09:58   279.312   144.219      33.038  238.881  922.112\n",
            "28  13 08:58   287.263   144.221      30.264  239.468  885.155\n",
            "29  13 20:58   319.737   144.829      30.280  263.285  857.394\n",
            "30  11 22:58   246.803   145.404      30.811  240.388  839.967\n",
            "31  11 23:58   231.144   146.174      31.650  238.490  839.972\n",
            "32  12 22:58   257.095   146.290      31.230  246.584  819.705\n",
            "33  12 08:58   243.624   146.413      32.453  233.190  930.062\n",
            "34  12 07:58   239.880   147.191      32.833  235.733  930.011\n",
            "35  12 00:58   220.564   147.361      30.994  241.004  839.875\n",
            "36  12 01:58   222.142   147.563      30.120  242.032  840.044\n",
            "37  12 06:58   221.983   147.680      32.976  240.944  865.000\n",
            "38  13 07:58   241.234   148.391      29.982  243.177  860.040\n",
            "39  12 02:58   206.502   149.084      28.460  243.747  839.911\n",
            "40  13 00:58   238.099   149.276      31.324  242.732  890.039\n",
            "41  12 23:58   236.230   149.469      31.596  241.016  900.541\n",
            "42  13 21:58   259.899   149.525      30.156  265.022  839.695\n",
            "43  13 22:58   221.842   150.281      29.863  246.590  845.424\n",
            "44  12 03:58   196.750   150.464      26.505  247.965  839.966\n",
            "45  13 23:58   218.371   150.559      29.836  247.065  849.862\n",
            "46  13 02:58   222.636   150.643      28.907  246.385  862.788\n",
            "47  13 01:58   220.819   150.969      29.833  244.445  889.918\n",
            "48  12 05:58   189.785   151.004      27.540  247.174  840.019\n",
            "49  12 04:58   187.100   151.439      26.352  248.577  839.902\n",
            "50  13 04:58   210.308   152.010      27.535  249.395  859.888\n",
            "51  13 03:58   205.620   152.138      28.353  247.321  860.006\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from torch import nn\n",
        "import matplotlib.pyplot as plt"
      ],
      "metadata": {
        "id": "O2JC_drhjqK4"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X = data_frame_Modified[['pressure','G_MW','Flow']].values\n",
        "y = data_frame_Modified['Steem MW']\n"
      ],
      "metadata": {
        "id": "kLgGTa7YkTx-"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "A2gU3_szahbu",
        "outputId": "2e41d622-d443-40a5-96d7-6f3fc0aa429b"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(52, 3)"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Create train/test split\n",
        "train_split = int(0.8 * len(X)) # 80% of data used for training set, 20% for testing\n",
        "X_train, y_train = X[:train_split], y[:train_split]\n",
        "X_test, y_test = X[train_split:], y[train_split:]\n",
        "\n",
        "len(X_train), len(y_train), len(X_test), len(y_test)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "btVRfaLEkPBX",
        "outputId": "de1bd4f0-f915-473d-9ce9-6213103c6596"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(41, 41, 11, 11)"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def plot_predictions(train_data=X_train,\n",
        "                     train_labels=y_train,\n",
        "                     test_data=X_test,\n",
        "                     test_labels=y_test,\n",
        "                     predictions=None):\n",
        "  \"\"\"\n",
        "  Plots training data, test data and compares predictions.\n",
        "  \"\"\"\n",
        "  plt.figure(figsize=(10, 7))\n",
        "\n",
        "  # Plot training data in blue\n",
        "  plt.scatter(train_data, train_labels, c=\"b\", s=4, label=\"Training data\")\n",
        "\n",
        "  # Plot test data in green\n",
        "  plt.scatter(test_data, test_labels, c=\"g\", s=4, label=\"Testing data\")\n",
        "\n",
        "  if predictions is not None:\n",
        "    # Plot the predictions in red (predictions were made on the test data)\n",
        "    plt.scatter(test_data, predictions, c=\"r\", s=4, label=\"Predictions\")\n",
        "\n",
        "  # Show the legend\n",
        "  plt.legend(prop={\"size\": 14});"
      ],
      "metadata": {
        "id": "RUtzB8Orj2Yn"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plot_predictions();"
      ],
      "metadata": {
        "id": "rTXcauSzkvGV",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 943
        },
        "outputId": "ce2ff647-dbb3-4f5a-b094-3fd720c75ab8"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-20-3e1129818439>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mplot_predictions\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m;\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-19-3efbd06fc700>\u001b[0m in \u001b[0;36mplot_predictions\u001b[0;34m(train_data, train_labels, test_data, test_labels, predictions)\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m   \u001b[0;31m# Plot training data in blue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m   \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscatter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_labels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mc\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"b\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ms\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"Training data\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m   \u001b[0;31m# Plot test data in green\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/matplotlib/pyplot.py\u001b[0m in \u001b[0;36mscatter\u001b[0;34m(x, y, s, c, marker, cmap, norm, vmin, vmax, alpha, linewidths, edgecolors, plotnonfinite, data, **kwargs)\u001b[0m\n\u001b[1;32m   2860\u001b[0m         \u001b[0mvmin\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvmax\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0malpha\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlinewidths\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2861\u001b[0m         edgecolors=None, plotnonfinite=False, data=None, **kwargs):\n\u001b[0;32m-> 2862\u001b[0;31m     __ret = gca().scatter(\n\u001b[0m\u001b[1;32m   2863\u001b[0m         \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ms\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mc\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmarker\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmarker\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcmap\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcmap\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnorm\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnorm\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2864\u001b[0m         \u001b[0mvmin\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvmin\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvmax\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvmax\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0malpha\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0malpha\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlinewidths\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlinewidths\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/matplotlib/__init__.py\u001b[0m in \u001b[0;36minner\u001b[0;34m(ax, data, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1440\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0minner\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0max\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1441\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mdata\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1442\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0max\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0mmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msanitize_sequence\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1443\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1444\u001b[0m         \u001b[0mbound\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnew_sig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbind\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0max\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/matplotlib/axes/_axes.py\u001b[0m in \u001b[0;36mscatter\u001b[0;34m(self, x, y, s, c, marker, cmap, norm, vmin, vmax, alpha, linewidths, edgecolors, plotnonfinite, **kwargs)\u001b[0m\n\u001b[1;32m   4582\u001b[0m         \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mma\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mravel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4583\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 4584\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"x and y must be the same size\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   4585\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4586\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0ms\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: x and y must be the same size"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1000x700 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class PowerPredictionModel(nn.Module):\n",
        "    def __init__(self, input_dim):\n",
        "        super(PowerPredictionModel, self).__init__()\n",
        "        self.fc1 = nn.Linear(input_dim, 32)  # Input layer to hidden layer\n",
        "        self.fc2 = nn.Linear(32, 16)         # Hidden layer to another hidden layer\n",
        "        self.fc3 = nn.Linear(16, 1)\n",
        "                  # Final hidden layer to output\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = torch.relu(self.fc1(x))\n",
        "        x = torch.relu(self.fc2(x))\n",
        "        x = self.fc3(x)\n",
        "        return x\n",
        "\n",
        "# Initialize the model\n",
        "input_dim = 3  # Number of input features\n",
        "model = PowerPredictionModel(input_dim)\n"
      ],
      "metadata": {
        "id": "EWb02V6XnIlh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.optim as optim"
      ],
      "metadata": {
        "id": "EsWfJMn8nWhE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "criterion = nn.MSELoss()  # Mean Squared Error loss\n",
        "optimizer_1 = optim.Adam(model.parameters(), lr=0.001)\n"
      ],
      "metadata": {
        "id": "quGzdn5fnMXg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "loss_fn = nn.BCEWithLogitsLoss()\n",
        "optimizer = torch.optim.SGD(model.parameters(), lr=0.1)"
      ],
      "metadata": {
        "id": "P2MMzINeDhyW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "num_epochs = 100\n",
        "for epoch in range(num_epochs):\n",
        "    inputs = torch.tensor(X_train, dtype=torch.float32).unsqueeze(dim=1)\n",
        "    targets = torch.tensor(y_train, dtype=torch.float32).unsqueeze(dim=1)\n",
        "    input_dim = inputs.size(dim=0)\n",
        "    optimizer_1.zero_grad()\n",
        "    outputs = model(inputs)\n",
        "    loss = criterion(outputs, targets)\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "    print(f'Epoch [{epoch + 1}/{num_epochs}], Loss: {loss.item():.4f}')\n"
      ],
      "metadata": {
        "id": "d2B3WtzdnaoS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.eval()\n",
        "with torch.no_grad():\n",
        "    test_inputs = torch.tensor(X_test, dtype=torch.float32).unsqueeze(dim=1)\n",
        "    predictions = model(test_inputs)\n",
        "\n",
        "# Calculate the evaluation metrics (e.g., RMSE, MAE)\n",
        "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
        "\n",
        "mse = mean_squared_error(y_test, predictions.numpy())\n",
        "rmse = mse ** 0.5\n",
        "mae = mean_absolute_error(y_test, predictions.numpy())\n",
        "\n",
        "print(f'RMSE: {rmse:.4f}, MAE: {mae:.4f}')\n"
      ],
      "metadata": {
        "id": "PjyyPXuAnihs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Setup device agnostic code\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "print(f\"Using device: {device}\")"
      ],
      "metadata": {
        "id": "KLwRqiT5id5C"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X1 = data_frame_Modified[['pressure']].values\n",
        "X2 = data_frame_Modified['G_MW'].values\n",
        "X3 = data_frame_Modified['Flow'].values"
      ],
      "metadata": {
        "id": "voeoVC5UTUPm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_split = int(0.8 * len(X)) # 80% of data used for training set, 20% for testing\n",
        "X1_train, X2_train, X3_train, y1_train = X1[:train_split], X2[:train_split], X3[:train_split], y[:train_split]\n",
        "X1_test, X2_test, X3_test, y1_test = X1[train_split:], X2[train_split:], X3[train_split:], y[train_split:]\n"
      ],
      "metadata": {
        "id": "Joi_wrD2T833"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from torch import nn\n",
        "class CircleModelV2(nn.Module):\n",
        "    def __init__(self, input_dim):\n",
        "        super().__init__()\n",
        "        self.features = nn.Sequential(\n",
        "          nn.Linear(in_features=input_dim, out_features=10),\n",
        "          nn.Linear(in_features=10, out_features=10),\n",
        "          nn.Linear(in_features=10, out_features=1),\n",
        "          nn.ReLU() # <- add in ReLU activation function\n",
        "          # Can also put sigmoid in the model\n",
        "          # This would mean you don't need to use it on the predictions\n",
        "          # self.sigmoid = nn.Sigmoid()\n",
        "        )\n",
        "\n",
        "    def forward(self, X1):\n",
        "      # Intersperse the ReLU activation function between layers\n",
        "      X1_feature = self.features(X1)\n",
        "      # X2_feature = self.features(X2)\n",
        "      # X3_feature = self.features(X3)\n",
        "      # return torch.cat((X1_feature, X2_feature, X3_feature), 1)\n",
        "      return X1_feature\n",
        "      #  return self.layer_3(self.relu(self.layer_2(self.relu(self.layer_1(x)))))\n",
        "\n",
        "model_3 = CircleModelV2(input_dim=1).to(device)\n",
        "print(model_3)\n",
        "model_3.state_dict()"
      ],
      "metadata": {
        "id": "IlJf_IU_iEAV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# import torch.optim as optim\n",
        "# # Create loss function\n",
        "# loss_fn = nn.L1Loss()\n",
        "\n",
        "# # Create optimizer\n",
        "# optimizer = torch.optim.SGD(params=model_3.parameters(), # optimize newly created model's parameters\n",
        "#                             lr=0.01)"
      ],
      "metadata": {
        "id": "2VYiBFy9f8Xb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Setup loss and optimizer\n",
        "loss_fn = nn.MSELoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.01)"
      ],
      "metadata": {
        "id": "EqqyyiBFifyE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Calculate accuracy (a classification metric)\n",
        "def accuracy_fn(y_true, y_pred):\n",
        "    correct = torch.eq(y_true, y_pred).sum().item() # torch.eq() calculates where two tensors are equal\n",
        "    acc = (correct / len(y_pred)) * 100\n",
        "    return acc"
      ],
      "metadata": {
        "id": "fNLjI9fjYSCK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_test = list(y_test)"
      ],
      "metadata": {
        "id": "0sFsUkKduKB-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X1_train, X1_test = torch.as_tensor(X1_train, dtype=torch.float32).to(device).unsqueeze(dim=1), torch.as_tensor(X1_test,  dtype=torch.float32).to(device).unsqueeze(dim=1)\n",
        "X2_train, X2_test = torch.as_tensor(X2_train, dtype=torch.float32).to(device).unsqueeze(dim=1), torch.as_tensor(X2_test, dtype=torch.float32).to(device).unsqueeze(dim=1)\n",
        "X3_train, X3_test = torch.as_tensor(X3_train).to(device).unsqueeze(dim=1), torch.as_tensor(X3_test).to(device).unsqueeze(dim=1)\n",
        "y_train, y_test = torch.as_tensor(y_train).to(device).unsqueeze(dim=1),  torch.as_tensor(y_test).to(device)\n"
      ],
      "metadata": {
        "id": "3xqWG9xAnBIS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X1_train.shape"
      ],
      "metadata": {
        "id": "v0El9ol9b7QZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Fit the model\n",
        "torch.manual_seed(42)\n",
        "epochs = 100\n",
        "\n",
        "# Put all data on target device\n",
        "\n",
        "for epoch in range(epochs):\n",
        "    model_3.train()\n",
        "    # 1. Forward pass\n",
        "    # y_logits = model_3(X1_train, X2_train, X3_train)\n",
        "    y_logits = model_3(X2_train )\n",
        "    y_pred = torch.round(torch.sigmoid(y_logits)) # logits -> prediction probabilities -> prediction labels\n",
        "    print(y_logits[1])\n",
        "    print(y_train[1])\n",
        "    # print(model_3.state_dict())\n",
        "    # 2. Calculate loss and accuracy\n",
        "    loss = loss_fn(y_logits, y_train).to(torch.float32) # BCEWithLogitsLoss calculates loss using logits\n",
        "    acc = accuracy_fn(y_true=y_train,\n",
        "                      y_pred=y_pred)\n",
        "\n",
        "    # 3. Optimizer zero grad\n",
        "    optimizer.zero_grad()\n",
        "\n",
        "    # 4. Loss backward\n",
        "    print(f\"loss: {loss.dtype}\")\n",
        "    loss.backward()\n",
        "\n",
        "    # 5. Optimizer step\n",
        "    optimizer.step()\n",
        "\n",
        "    ### Testing\n",
        "    model_3.eval()\n",
        "    with torch.inference_mode():\n",
        "      # 1. Forward pass\n",
        "      test_logits = model_3(X2_test).squeeze()\n",
        "      test_pred = torch.round(torch.sigmoid(test_logits)) # logits -> prediction probabilities -> prediction labels\n",
        "      # 2. Calcuate loss and accuracy\n",
        "      test_loss = loss_fn(test_logits.unsqueeze(dim=1), y_test)\n",
        "      test_acc = accuracy_fn(y_true=y_test,\n",
        "                             y_pred=test_pred)\n",
        "\n",
        "    # Print out what's happening\n",
        "    if epoch % 10 == 0:\n",
        "        print(f\"Epoch: {epoch} | Loss: {loss:.5f}, Accuracy: {acc:.2f}% | Test Loss: {test_loss:.5f}, Test Accuracy: {test_acc:.2f}%\")"
      ],
      "metadata": {
        "id": "HcwyboYPiypk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_test.shape"
      ],
      "metadata": {
        "id": "MMF9a9mZESiR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_3"
      ],
      "metadata": {
        "id": "mBrkRJ-QCxRY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "CkKZheHgCxGm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_3.state_dict()"
      ],
      "metadata": {
        "id": "uLuNFE1IBYW5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Subclass nn.Module to make our model\n",
        "class LinearRegressionModelV2(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        # Use nn.Linear() for creating the model parameters\n",
        "        self.linear_layer = nn.Linear(in_features=1,\n",
        "                                      out_features=1)\n",
        "\n",
        "    # Define the forward computation (input data x flows through nn.Linear())\n",
        "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
        "        return self.linear_layer(x)\n",
        "\n",
        "# Set the manual seed when creating the model (this isn't always need but is used for demonstrative purposes, try commenting it out and seeing what happens)\n",
        "torch.manual_seed(42)\n",
        "model_1 = LinearRegressionModelV2()\n",
        "model_1, model_1.state_dict()"
      ],
      "metadata": {
        "id": "DjnPo_3s4VYh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X2_train = X2_train\n",
        "X2_test = X2_test\n",
        "y_test = y_test.unsqueeze(dim=1)"
      ],
      "metadata": {
        "id": "-cEnl1p57GDr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "epochs = 1000\n",
        "for epoch in range(epochs):\n",
        "    ### Training\n",
        "    model_1.train() # train mode is on by default after construction\n",
        "\n",
        "    # 1. Forward pass\n",
        "    y_pred = model_1(X2_train)\n",
        "\n",
        "    # 2. Calculate loss\n",
        "    loss = loss_fn(y_pred, y_train)\n",
        "\n",
        "    # 3. Zero grad optimizer\n",
        "    optimizer.zero_grad()\n",
        "\n",
        "    # 4. Loss backward\n",
        "    loss.backward()\n",
        "\n",
        "    # 5. Step the optimizer\n",
        "    optimizer.step()\n",
        "\n",
        "    ### Testing\n",
        "    model_1.eval() # put the model in evaluation mode for testing (inference)\n",
        "    # 1. Forward pass\n",
        "    with torch.inference_mode():\n",
        "        test_pred = model_1(X2_test)\n",
        "\n",
        "        # 2. Calculate the loss\n",
        "        test_loss = loss_fn(test_pred, y_test)\n",
        "\n",
        "    if epoch % 100 == 0:\n",
        "        print(f\"Epoch: {epoch} | Train loss: {loss} | Test loss: {test_loss}\")"
      ],
      "metadata": {
        "id": "jmVYayv24jHk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_pred.shape"
      ],
      "metadata": {
        "id": "fUGqelRVGxwN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "\n",
        "train_split = int(0.8 * len(X)) # 80% of data used for training set, 20% for testing\n",
        "X_train, y_train = X[:train_split], y[:train_split]\n",
        "X_test, y_test = X[train_split:], y[train_split:]\n",
        "\n",
        "# Data Preprocessing\n",
        "data = ...  # Your data here\n",
        "pressure_1 = data_frame_Modified['pressure'].values.reshape(-1, 1)\n",
        "steem_mw_1 = data_frame_Modified['Steem MW'].values.reshape(-1, 1)\n",
        "pressure = pressure_1[:train_split]\n",
        "steem_mw = steem_mw_1[:train_split]\n",
        "test_pressure = pressure_1[train_split:]  # Remaining data for testing\n",
        "test_steem_mw = steem_mw_1[train_split:]  # Corresponding \"Steem MW\" values for testing\n",
        "print(train_split)\n",
        "print(test_pressure)\n",
        "scaler = MinMaxScaler()\n",
        "pressure = scaler.fit_transform(pressure)\n",
        "steem_mw = scaler.fit_transform(steem_mw)\n",
        "\n",
        "# Model Architecture\n",
        "class RegressionModel(nn.Module):\n",
        "    def __init__(self, input_dim):\n",
        "        super(RegressionModel, self).__init__()\n",
        "        self.linear = nn.Linear(input_dim, 1)\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.linear(x)\n",
        "\n",
        "input_dim = 1  # Only the 'pressure' feature\n",
        "model = RegressionModel(input_dim)\n",
        "\n",
        "# Loss Function and Optimizer\n",
        "criterion = nn.MSELoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.01)\n",
        "\n",
        "# Training Loop\n",
        "num_epochs = 100\n",
        "for epoch in range(num_epochs):\n",
        "    inputs = torch.tensor(pressure, dtype=torch.float32)\n",
        "    targets = torch.tensor(steem_mw, dtype=torch.float32)\n",
        "\n",
        "    optimizer.zero_grad()\n",
        "    outputs = model(inputs)\n",
        "    loss = criterion(outputs, targets)\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "    if epoch % 10 == 0:\n",
        "        print(f'Epoch [{epoch+1}/{num_epochs}], Loss: {loss.item():.4f}')\n",
        "\n",
        "# Make Predictions\n",
        "model.eval()\n",
        "with torch.no_grad():\n",
        "    print(test_pressure.shape )\n",
        "    normalized_test_pressure = scaler.transform(test_pressure)\n",
        "    predicted_steem_mw = model(torch.tensor(normalized_test_pressure, dtype=torch.float32)).numpy()\n",
        "    predicted_steem_mw = scaler.inverse_transform(predicted_steem_mw)\n",
        "    print(predicted_steem_mw)\n",
        "# Evaluate the model's predictions\n",
        "# You can use metrics like MAE or RMSE to assess the model's performance.\n"
      ],
      "metadata": {
        "id": "dX86YElrqdPP",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d72de103-5ab8-44a2-c130-aa16e76232a1"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "41\n",
            "[[236.23 ]\n",
            " [259.899]\n",
            " [221.842]\n",
            " [196.75 ]\n",
            " [218.371]\n",
            " [222.636]\n",
            " [220.819]\n",
            " [189.785]\n",
            " [187.1  ]\n",
            " [210.308]\n",
            " [205.62 ]]\n",
            "Epoch [1/100], Loss: 3.9881\n",
            "Epoch [11/100], Loss: 3.3846\n",
            "Epoch [21/100], Loss: 2.8407\n",
            "Epoch [31/100], Loss: 2.3605\n",
            "Epoch [41/100], Loss: 1.9441\n",
            "Epoch [51/100], Loss: 1.5888\n",
            "Epoch [61/100], Loss: 1.2896\n",
            "Epoch [71/100], Loss: 1.0410\n",
            "Epoch [81/100], Loss: 0.8371\n",
            "Epoch [91/100], Loss: 0.6718\n",
            "(11, 1)\n",
            "[[127.61402]\n",
            " [126.44748]\n",
            " [128.32314]\n",
            " [129.5598 ]\n",
            " [128.49419]\n",
            " [128.284  ]\n",
            " [128.37355]\n",
            " [129.90306]\n",
            " [130.0354 ]\n",
            " [128.89159]\n",
            " [129.12263]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "\n",
        "train_split = int(0.8 * len(X)) # 80% of data used for training set, 20% for testing\n",
        "\n",
        "pressure_1 = data_frame_Modified['pressure'].values.reshape(-1, 1)\n",
        "Flow_1 = data_frame_Modified['Flow'].values.reshape(-1, 1)\n",
        "G_MW_1 = data_frame_Modified['G_MW'].values.reshape(-1, 1)\n",
        "\n",
        "pressure = pressure_1[:train_split]\n",
        "Flow = Flow_1[:train_split]\n",
        "G_MW = G_MW_1[:train_split]\n",
        "\n",
        "test_pressure = pressure_1[train_split:]\n",
        "test_Flow = Flow_1[train_split:]\n",
        "test_G_MW = G_MW_1[train_split:]\n",
        "\n",
        "scaler = MinMaxScaler()\n",
        "pressure = scaler.fit_transform(pressure)\n",
        "Flow = scaler.fit_transform(Flow)\n",
        "G_MW = scaler.fit_transform(G_MW)\n",
        "\n",
        "# Model Architecture\n",
        "class RegressionModel(nn.Module):\n",
        "    def __init__(self, input_dim):\n",
        "        super(RegressionModel, self).__init__()\n",
        "        self.linear = nn.Linear(input_dim, 1)\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.linear(x)\n",
        "\n",
        "input_dim = 3  # Only the 'pressure' feature\n",
        "model = RegressionModel(input_dim)\n",
        "\n",
        "# Loss Function and Optimizer\n",
        "criterion = nn.MSELoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.01)\n",
        "\n",
        "# Training Loop\n",
        "num_epochs = 100\n",
        "for epoch in range(num_epochs):\n",
        "    inputs = torch.tensor(\n",
        "        np.column_stack((pressure, Flow, G_MW)),\n",
        "        dtype=torch.float32\n",
        "    )\n",
        "    targets = torch.tensor(steem_mw, dtype=torch.float32)\n",
        "\n",
        "    optimizer.zero_grad()\n",
        "    outputs = model(inputs)\n",
        "    loss = criterion(outputs, targets)\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "    if epoch % 10 == 0:\n",
        "        print(f'Epoch [{epoch+1}/{num_epochs}], Loss: {loss.item():.4f}')\n",
        "\n",
        "# Make Predictions\n",
        "model.eval()\n",
        "with torch.no_grad():\n",
        "    print(test_pressure.shape )\n",
        "    normalized_test_pressure = scaler.transform(test_pressure)\n",
        "    normalized_test_Flow = scaler.transform(test_Flow)\n",
        "    normalized_test_G_MW = scaler.transform(test_G_MW)\n",
        "\n",
        "    normalized_test_inputs = np.column_stack(\n",
        "        (normalized_test_pressure, normalized_test_Flow, normalized_test_G_MW)\n",
        "    )\n",
        "\n",
        "    predicted_steem_mw = model(torch.tensor(normalized_test_inputs, dtype=torch.float32)).numpy()\n",
        "    print(predicted_steem_mw)\n",
        "    predicted_steem_mw = scaler.inverse_transform(predicted_steem_mw)\n",
        "    print(predicted_steem_mw)\n",
        "\n",
        "# Evaluate the model's predictions\n",
        "# You can use metrics like MAE or RMSE to assess the model's performance."
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "x2meA_JP8JNV",
        "outputId": "887b9f45-37e4-49cf-9028-9ac8f3482820"
      },
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [1/100], Loss: 0.2657\n",
            "Epoch [11/100], Loss: 0.1605\n",
            "Epoch [21/100], Loss: 0.1337\n",
            "Epoch [31/100], Loss: 0.1037\n",
            "Epoch [41/100], Loss: 0.0807\n",
            "Epoch [51/100], Loss: 0.0624\n",
            "Epoch [61/100], Loss: 0.0486\n",
            "Epoch [71/100], Loss: 0.0386\n",
            "Epoch [81/100], Loss: 0.0315\n",
            "Epoch [91/100], Loss: 0.0267\n",
            "(11, 1)\n",
            "[[12.058666]\n",
            " [10.895791]\n",
            " [11.0934  ]\n",
            " [11.030042]\n",
            " [11.175705]\n",
            " [11.39938 ]\n",
            " [11.88551 ]\n",
            " [11.042794]\n",
            " [11.041427]\n",
            " [11.359121]\n",
            " [11.37264 ]]\n",
            "[[690.68036]\n",
            " [645.7375 ]\n",
            " [653.3747 ]\n",
            " [650.926  ]\n",
            " [656.55566]\n",
            " [665.20026]\n",
            " [683.98816]\n",
            " [651.4189 ]\n",
            " [651.366  ]\n",
            " [663.64435]\n",
            " [664.16675]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import MinMaxScaler\n",
        "\n",
        "# Assuming you have separate scalers for pressure, temperature, and humidity\n",
        "scaler_pressure = MinMaxScaler()\n",
        "scaler_Flow = MinMaxScaler()\n",
        "scaler_G_MW = MinMaxScaler()\n",
        "\n",
        "# Fit each scaler to the corresponding feature\n",
        "scaler_pressure.fit(pressure)\n",
        "scaler_Flow.fit(Flow)\n",
        "scaler_G_MW.fit(G_MW)\n",
        "\n",
        "# Generate a new sample\n",
        "new_pressure = 120\n",
        "new_Flow = 450\n",
        "new_G_MW = 300\n",
        "\n",
        "# Scale the new sample using the corresponding scaler\n",
        "normalized_new_pressure = scaler_pressure.transform([[new_pressure]])\n",
        "normalized_new_Flow = scaler_Flow.transform([[new_Flow]])\n",
        "normalized_new_G_MW = scaler_G_MW.transform([[new_G_MW]])\n",
        "\n",
        "# Combine the normalized features into a single array\n",
        "new_samples = np.array([[new_pressure, new_Flow, new_G_MW]])\n",
        "\n",
        "# Scale the new sample using the corresponding scalers\n",
        "normalized_new_samples = np.column_stack((\n",
        "    scaler_pressure.transform([[new_pressure]]),\n",
        "    scaler_Flow.transform([[new_Flow]]),\n",
        "    scaler_G_MW.transform([[new_G_MW]])\n",
        "))\n",
        "\n",
        "# Make predictions using the model\n",
        "model.eval()\n",
        "with torch.no_grad():\n",
        "    inputs = torch.tensor(normalized_new_samples, dtype=torch.float32)\n",
        "    print(inputs)\n",
        "    predicted_steem_mw = model(inputs).numpy()\n",
        "    print(predicted_steem_mw)\n",
        "    predicted_steem_mw = scaler.inverse_transform(predicted_steem_mw)\n",
        "\n",
        "# Print the predicted Steem MW value\n",
        "print(f\"Predicted Steem MW: {predicted_steem_mw[0][0]:.2f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VkBuN9yi_otD",
        "outputId": "cfc24fd5-6493-4650-e0e8-47dc196cc321"
      },
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[120., 450., 300.]])\n",
            "[[243.04503]]\n",
            "Predicted Steem MW: 9617.84\n"
          ]
        }
      ]
    }
  ]
}